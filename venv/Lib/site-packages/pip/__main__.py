import os
import gdown
import zipfile
from classificadorModelos import build_model1, build_model2, build_transfer_model1, build_transfer_model2
from classificadorTreinamento import preprocess_dataset, train_model
from tensorflow.keras.preprocessing.image import ImageDataGenerator

# Baixe e extraia o conjunto de dados
file_id = "1kFTbuI89jrtVw_DfjL9UZsPInFhGr4px"
output_file = "data/Dataset.zip"

if not os.path.exists(output_file):
    gdown.download(f"https://drive.google.com/uc?id={file_id}", output_file)

    with zipfile.ZipFile(output_file, 'r') as zip_ref:
        zip_ref.extractall("data/")

# Crie geradores de dados
datagen = ImageDataGenerator(rescale=1./255, shear_range=0.2, zoom_range=0.2, horizontal_flip=True)
train_generator = datagen.flow_from_directory('data/treinamento', target_size=(224, 224), batch_size=32, class_mode='categorical')
validation_generator = datagen.flow_from_directory('data/validacao', target_size=(224, 224), batch_size=32, class_mode='categorical')

# Treine os modelos
model1 = build_model1()
history1 = train_model(model1, train_generator, validation_generator)

model2 = build_model2()
history2 = train_model(model2, train_generator, validation_generator)

model_transfer1 = build_transfer_model1()
history_transfer1 = train_model(model_transfer1, train_generator, validation_generator)

model_transfer2 = build_transfer_model2()
history_transfer2 = train_model(model_transfer2, train_generator, validation_generator)
